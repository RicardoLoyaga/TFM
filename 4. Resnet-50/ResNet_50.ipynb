{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "dCPsB-9kt_Al",
        "outputId": "3c68d6f1-e145-4d1e-ae2d-01dc5a4bb994"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/EnfermedadesCacao/train/labels.cache'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-608149935.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Crear los datasets y dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-608149935.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, transform)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mcls_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/EnfermedadesCacao/train/labels.cache'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. Definición de la Clase de Dataset ---\n",
        "\n",
        "class ImageClassificationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- 2. Configuración del Modelo ---\n",
        "\n",
        "def get_resnet_model(num_classes):\n",
        "    # Cargar un modelo ResNet-50 pre-entrenado\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "\n",
        "    # Congelar los parámetros de las capas pre-entrenadas para no modificarlas\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Reemplazar la última capa de clasificación para que se ajuste a nuestras clases\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "# --- 3. Bucle de Entrenamiento ---\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Solo entrenar la última capa\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Evaluación en el set de validación\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Época [{epoch+1}/{num_epochs}], Pérdida: {epoch_loss:.4f}, Precisión de Validación: {accuracy:.2f}%')\n",
        "\n",
        "    print('Entrenamiento completado.')\n",
        "\n",
        "# --- Configuración principal y ejecución ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Asegúrate de que tus directorios de datos tengan esta estructura:\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/train/Fito\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/train/Monilia\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/train/Sana\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/val/Fito\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/val/Monilia\n",
        "    # /content/drive/MyDrive/EnfermedadesCacao/val/Sana\n",
        "\n",
        "    data_root = '/content/drive/MyDrive/EnfermedadesCacao'\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    val_dir = os.path.join(data_root, 'val')\n",
        "    num_classes = 3  # Fito, Monilia, Sana\n",
        "\n",
        "    # Transformaciones de datos\n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # Crear los datasets y dataloaders\n",
        "    train_dataset = ImageClassificationDataset(root_dir=train_dir, transform=image_transforms)\n",
        "    val_dataset = ImageClassificationDataset(root_dir=val_dir, transform=image_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Inicializar el modelo y el dispositivo\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = get_resnet_model(num_classes)\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    train_model(model, train_loader, val_loader, num_epochs=10, device=device)\n",
        "\n",
        "    # Opcional: Guardar el modelo entrenado\n",
        "    torch.save(model.state_dict(), 'resnet50_cocoa_pests.pth')\n",
        "    print(\"Modelo guardado como resnet50_cocoa_pests.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. Definición de la Clase de Dataset (CORREGIDA) ---\n",
        "\n",
        "class ImageClassificationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filtrar solo los directorios que representan las clases\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- 2. Configuración del Modelo ---\n",
        "\n",
        "def get_resnet_model(num_classes):\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# --- 3. Bucle de Entrenamiento ---\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Época [{epoch+1}/{num_epochs}], Pérdida: {epoch_loss:.4f}, Precisión de Validación: {accuracy:.2f}%')\n",
        "\n",
        "    print('Entrenamiento completado.')\n",
        "\n",
        "# --- Configuración principal y ejecución ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_root = '/content/drive/MyDrive/EnfermedadesCacao'\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    val_dir = os.path.join(data_root, 'val')\n",
        "    num_classes = 3  # Fito, Monilia, Sana\n",
        "\n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageClassificationDataset(root_dir=train_dir, transform=image_transforms)\n",
        "    val_dataset = ImageClassificationDataset(root_dir=val_dir, transform=image_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = get_resnet_model(num_classes)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, num_epochs=10, device=device)\n",
        "\n",
        "    torch.save(model.state_dict(), 'resnet50_cocoa_pests.pth')\n",
        "    print(\"Modelo guardado como resnet50_cocoa_pests.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "7vJa-WSXuzmF",
        "outputId": "85165b2c-6272-41fd-de0b-a162ee72505e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnidentifiedImageError",
          "evalue": "Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipython-input-4147141329.py\", line 32, in __getitem__\n    image = Image.open(img_path).convert('RGB')\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3580, in open\n    raise UnidentifiedImageError(msg)\nPIL.UnidentifiedImageError: cannot identify image file '/content/drive/MyDrive/EnfermedadesCacao/train/labels/Monilia59.txt'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4147141329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet50_cocoa_pests.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4147141329.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# be constructed, don't try to instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: Caught UnidentifiedImageError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/tmp/ipython-input-4147141329.py\", line 32, in __getitem__\n    image = Image.open(img_path).convert('RGB')\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/PIL/Image.py\", line 3580, in open\n    raise UnidentifiedImageError(msg)\nPIL.UnidentifiedImageError: cannot identify image file '/content/drive/MyDrive/EnfermedadesCacao/train/labels/Monilia59.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Correcion del código para mantener la estructura de los otros modelos y solo leer imagenes"
      ],
      "metadata": {
        "id": "Nvt7DR-TvFq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import time\n",
        "\n",
        "# --- 1. Definición de la Clase de Dataset (CORREGIDA) ---\n",
        "\n",
        "class ImageClassificationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filtrar solo los directorios que representan las clases\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                # Solo procesar si el archivo tiene una extensión de imagen común\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                    self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "                # Ignorar cualquier otro archivo, como .txt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- 2. Configuración del Modelo ---\n",
        "\n",
        "def get_resnet_model(num_classes):\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# --- 3. Bucle de Entrenamiento ---\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f'Época [{epoch+1}/{num_epochs}], Pérdida: {epoch_loss:.4f}, Precisión de Validación: {accuracy:.2f}%')\n",
        "\n",
        "    print('Entrenamiento completado.')\n",
        "\n",
        "# --- Configuración principal y ejecución ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_root = '/content/drive/MyDrive/EnfermedadesCacao'\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    val_dir = os.path.join(data_root, 'val')\n",
        "    num_classes = 3\n",
        "\n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageClassificationDataset(root_dir=train_dir, transform=image_transforms)\n",
        "    val_dataset = ImageClassificationDataset(root_dir=val_dir, transform=image_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = get_resnet_model(num_classes)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, num_epochs=10, device=device)\n",
        "\n",
        "    torch.save(model.state_dict(), 'resnet50_cocoa_pests.pth')\n",
        "    print(\"Modelo guardado como resnet50_cocoa_pests.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9uDVLaQvFQ2",
        "outputId": "a15fd034-3ff9-47cb-c837-ec6e39a75beb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [1/10], Pérdida: 0.5459, Precisión de Validación: 100.00%\n",
            "Época [2/10], Pérdida: 0.0948, Precisión de Validación: 100.00%\n",
            "Época [3/10], Pérdida: 0.0253, Precisión de Validación: 100.00%\n",
            "Época [4/10], Pérdida: 0.0127, Precisión de Validación: 100.00%\n",
            "Época [5/10], Pérdida: 0.0079, Precisión de Validación: 100.00%\n",
            "Época [6/10], Pérdida: 0.0054, Precisión de Validación: 100.00%\n",
            "Época [7/10], Pérdida: 0.0060, Precisión de Validación: 100.00%\n",
            "Época [8/10], Pérdida: 0.0075, Precisión de Validación: 100.00%\n",
            "Época [9/10], Pérdida: 0.0055, Precisión de Validación: 100.00%\n",
            "Época [10/10], Pérdida: 0.0046, Precisión de Validación: 100.00%\n",
            "Entrenamiento completado.\n",
            "Modelo guardado como resnet50_cocoa_pests.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Inclusion de metricas para valorar el modelo"
      ],
      "metadata": {
        "id": "wORIfLkcw8Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# --- 1. Definición de la Clase de Dataset (sin cambios) ---\n",
        "class ImageClassificationDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                    self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# --- 2. Configuración del Modelo (sin cambios) ---\n",
        "def get_resnet_model(num_classes):\n",
        "    model = models.resnet50(weights='DEFAULT')\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "# --- 3. Bucle de Entrenamiento (sin cambios) ---\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Evaluación en el set de validación\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Época [{epoch+1}/{num_epochs}], Pérdida: {epoch_loss:.4f}, Precisión de Validación: {accuracy:.2f}%')\n",
        "    print('Entrenamiento completado.')\n",
        "\n",
        "# --- 4. Nueva Función para Evaluación de Métricas y Gráficas ---\n",
        "def evaluate_model(model, val_loader, class_names, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Generar y mostrar la Matriz de Confusión\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Matriz de Confusión', fontsize=16)\n",
        "    plt.ylabel('Clase Real', fontsize=12)\n",
        "    plt.xlabel('Clase Predicha', fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "    # Calcular y mostrar las métricas de Precisión, Recall y F1-Score\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
        "\n",
        "    print(\"\\n--- Métricas por Clase ---\")\n",
        "    for i, name in enumerate(class_names):\n",
        "        print(f\"Clase: {name}\")\n",
        "        print(f\"  Precisión: {precision[i]:.4f}\")\n",
        "        print(f\"  Recall:    {recall[i]:.4f}\")\n",
        "        print(f\"  F1-Score:  {f1_score[i]:.4f}\")\n",
        "\n",
        "    # Calcular métricas globales (promedio)\n",
        "    avg_precision = precision.mean()\n",
        "    avg_recall = recall.mean()\n",
        "    avg_f1 = f1_score.mean()\n",
        "\n",
        "    print(\"\\n--- Métricas Globales (Promedio) ---\")\n",
        "    print(f\"Precisión Promedio: {avg_precision:.4f}\")\n",
        "    print(f\"Recall Promedio:    {avg_recall:.4f}\")\n",
        "    print(f\"F1-Score Promedio:  {avg_f1:.4f}\")\n",
        "\n",
        "# --- Configuración principal y ejecución ---\n",
        "if __name__ == '__main__':\n",
        "    data_root = '/content/drive/MyDrive/EnfermedadesCacao'\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    val_dir = os.path.join(data_root, 'val')\n",
        "    class_names = ['Fito', 'Monilia', 'Sana']\n",
        "    num_classes = len(class_names)\n",
        "\n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    train_dataset = ImageClassificationDataset(root_dir=train_dir, transform=image_transforms)\n",
        "    val_dataset = ImageClassificationDataset(root_dir=val_dir, transform=image_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = get_resnet_model(num_classes)\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    train_model(model, train_loader, val_loader, num_epochs=10, device=device)\n",
        "\n",
        "    # Evaluar y graficar los resultados\n",
        "    evaluate_model(model, val_loader, class_names, device)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ducZBZ5Qw6_-",
        "outputId": "0f2ab090-eb23-49a8-b8eb-475c38cd47b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [1/10], Pérdida: 0.5894, Precisión de Validación: 100.00%\n",
            "Época [2/10], Pérdida: 0.0748, Precisión de Validación: 100.00%\n",
            "Época [3/10], Pérdida: 0.0244, Precisión de Validación: 100.00%\n",
            "Época [4/10], Pérdida: 0.0156, Precisión de Validación: 100.00%\n",
            "Época [5/10], Pérdida: 0.0100, Precisión de Validación: 100.00%\n",
            "Época [6/10], Pérdida: 0.0063, Precisión de Validación: 100.00%\n",
            "Época [7/10], Pérdida: 0.0053, Precisión de Validación: 100.00%\n",
            "Época [8/10], Pérdida: 0.0059, Precisión de Validación: 100.00%\n",
            "Época [9/10], Pérdida: 0.0046, Precisión de Validación: 100.00%\n",
            "Época [10/10], Pérdida: 0.0048, Precisión de Validación: 100.00%\n",
            "Entrenamiento completado.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Métricas por Clase ---\n",
            "Clase: Fito\n",
            "  Precisión: 1.0000\n",
            "  Recall:    1.0000\n",
            "  F1-Score:  1.0000\n",
            "Clase: Monilia\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for axis 0 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-590330071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# Evaluar y graficar los resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-590330071.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, val_loader, class_names, device)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Clase: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Precisión: {precision[i]:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Recall:    {recall[i]:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  F1-Score:  {f1_score[i]:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    }
  ]
}